{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_name = 'train_untrained_bert_tabular.p'\n",
    "test_name = 'test_untrained_bert_tabular.p'\n",
    "\n",
    "with open(train_name, 'rb') as fp:\n",
    "    train_data = pickle.load(fp)\n",
    "\n",
    "with open(test_name, 'rb') as fp:\n",
    "    test_data = pickle.load(fp)\n",
    "    \n",
    "with open('test_comps_tabular.p', 'rb') as fp:\n",
    "    test_comps = pickle.load(fp)\n",
    "    \n",
    "with open('enc_states_sync_all.p', 'rb') as fp:\n",
    "    all_comps = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "graph = pd.read_csv('vertices.csv')\n",
    "\n",
    "meta = pd.read_csv('kernels_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_vertex_id</th>\n",
       "      <th>graph_vertex_class</th>\n",
       "      <th>graph_vertex_subclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hyperparam_Tuning</td>\n",
       "      <td>find_best_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hyperparam_Tuning</td>\n",
       "      <td>find_best_params</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hyperparam_Tuning</td>\n",
       "      <td>find_best_model_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Model_Train</td>\n",
       "      <td>choose_model_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hyperparam_Tuning</td>\n",
       "      <td>define_search_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>88</td>\n",
       "      <td>Debug</td>\n",
       "      <td>list_files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>91</td>\n",
       "      <td>Data_Extraction</td>\n",
       "      <td>prepare_data_loader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>92</td>\n",
       "      <td>Visualization</td>\n",
       "      <td>plot_metrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>93</td>\n",
       "      <td>Visualization</td>\n",
       "      <td>images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>94</td>\n",
       "      <td>Model_Train</td>\n",
       "      <td>build_layers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    graph_vertex_id graph_vertex_class  graph_vertex_subclass\n",
       "0                 1  Hyperparam_Tuning        find_best_score\n",
       "1                 2  Hyperparam_Tuning       find_best_params\n",
       "2                 3  Hyperparam_Tuning  find_best_model_class\n",
       "3                 4        Model_Train     choose_model_class\n",
       "4                 5  Hyperparam_Tuning    define_search_space\n",
       "..              ...                ...                    ...\n",
       "70               88              Debug             list_files\n",
       "71               91    Data_Extraction    prepare_data_loader\n",
       "72               92      Visualization           plot_metrics\n",
       "73               93      Visualization                 images\n",
       "74               94        Model_Train           build_layers\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in test_data:\n",
    "#     print([graph[graph.graph_vertex_id == x]['graph_vertex_subclass'].values[0] for x in sample['target'].numpy() if x < 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kernel_id', 'encoded_sequence', 'encoded_tokens', 'target', 'classes', 'comp_name', 'weight'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([788])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][\"encoded_sequence\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(note[\"target\"]) for note in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(note[\"target\"]) for note in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 34, 35, 38, 40, 41, 42, 43, 44, 45, 47, 48, 52, 53, 54, 57, 58, 61, 62, 66, 68, 69, 75, 76]\n"
     ]
    }
   ],
   "source": [
    "val = set()\n",
    "\n",
    "for note in train_data:\n",
    "    val = val | set(note[\"target\"].numpy())\n",
    "    \n",
    "for note in test_data:\n",
    "    val = val | set(note[\"target\"].numpy())\n",
    "\n",
    "val = list(val)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "def test(X_train, X_test, y_train, y_test):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(\"R^2:\", pipe.score(X_test, y_test))\n",
    "    print(\"MSE:\", MSE(pipe.predict(X_test), y_test))\n",
    "    print(\"MAE:\", MAE(pipe.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9702744177313025\n",
      "MSE: 5278753573.952385\n",
      "MAE: 9446.60715717088\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "for note in train_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    X_train.append(note[\"encoded_sequence\"].numpy())\n",
    "    y_train.append(score)\n",
    "        \n",
    "for note in test_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    X_test.append(note[\"encoded_sequence\"].numpy())\n",
    "    y_test.append(score)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9406659012905054\n",
      "MSE: 0.009405832059876109\n",
      "MAE: 0.02587763001440488\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "for note in train_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    if score >= 1:\n",
    "        continue\n",
    "    X_train.append(note[\"encoded_sequence\"].numpy())\n",
    "    y_train.append(score)\n",
    "        \n",
    "for note in test_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    if score >= 1:\n",
    "        continue\n",
    "    X_test.append(note[\"encoded_sequence\"].numpy())\n",
    "    y_test.append(score)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9411299821051287\n",
      "MSE: 0.009332264477330893\n",
      "MAE: 0.02586866078512514\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "for note in train_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    if score >= 1:\n",
    "        continue\n",
    "    X_train.append(np.append(note[\"encoded_sequence\"].numpy(), len(note[\"target\"])))\n",
    "    y_train.append(score)\n",
    "        \n",
    "for note in test_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    if score >= 1:\n",
    "        continue\n",
    "    X_test.append(np.append(note[\"encoded_sequence\"].numpy(), len(note[\"target\"])))\n",
    "    y_test.append(score)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.7587831692422214\n",
      "MSE: 42835971923.112366\n",
      "MAE: 41654.77639876845\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "for note in train_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    \n",
    "    target = note[\"target\"]\n",
    "    target_len = len(target)\n",
    "    target = target[:max_len]\n",
    "    target = np.pad(target, (0, max_len - len(target)),  \"constant\", constant_values = -1)\n",
    "    \n",
    "    X_train.append(np.append(\n",
    "        note[\"encoded_sequence\"], np.append(target, target_len)\n",
    "    ))\n",
    "    \n",
    "    y_train.append(score)\n",
    "    \n",
    "    bad_target_len = np.random.randint(max_len)\n",
    "    bad_target = np.random.choice(val, bad_target_len, True)\n",
    "    bad_target = np.pad(bad_target, (0, max_len - len(bad_target)),  \"constant\", constant_values = -1)\n",
    "    \n",
    "    X_train.append(np.append(\n",
    "        note[\"encoded_sequence\"], np.append(bad_target, bad_target_len)\n",
    "    ))\n",
    "    \n",
    "    if score < 1:\n",
    "        y_train.append(np.random.uniform(0.0, 0.01))\n",
    "    else:\n",
    "        y_train.append(np.random.uniform(0.0, 1000))\n",
    "        \n",
    "for note in test_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    \n",
    "    target = note[\"target\"]\n",
    "    target_len = len(target)\n",
    "    target = target[:max_len]\n",
    "    target = np.pad(target, (0, max_len - len(target)),  \"constant\", constant_values = -1)\n",
    "    \n",
    "    X_test.append(np.append(\n",
    "        note[\"encoded_sequence\"], np.append(target, target_len)\n",
    "    ))\n",
    "    \n",
    "    y_test.append(score)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "\n",
    "for note in train_data:\n",
    "    func = note[\"encoded_sequence\"][-20:].argmax().item()\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    \n",
    "    if scores.get(func) is None:\n",
    "        scores[func] = []\n",
    "    \n",
    "    scores[func].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "count    618.000000\n",
      "mean       0.819965\n",
      "std        0.168674\n",
      "min        0.056730\n",
      "25%        0.782000\n",
      "50%        0.843500\n",
      "75%        0.937975\n",
      "max        1.000000\n",
      "dtype: float64\n",
      "==================================================\n",
      "16\n",
      "count    563.000000\n",
      "mean       0.461181\n",
      "std        1.307298\n",
      "min        0.000000\n",
      "25%        0.121465\n",
      "50%        0.130780\n",
      "75%        0.475705\n",
      "max       20.687910\n",
      "dtype: float64\n",
      "==================================================\n",
      "17\n",
      "count    194.000000\n",
      "mean       0.166770\n",
      "std        0.255111\n",
      "min        0.000000\n",
      "25%        0.035160\n",
      "50%        0.046000\n",
      "75%        0.067290\n",
      "max        0.751970\n",
      "dtype: float64\n",
      "==================================================\n",
      "6\n",
      "count    224.000000\n",
      "mean       0.305926\n",
      "std        0.699558\n",
      "min        0.017990\n",
      "25%        0.018427\n",
      "50%        0.018680\n",
      "75%        0.019000\n",
      "max        2.491360\n",
      "dtype: float64\n",
      "==================================================\n",
      "9\n",
      "count    2.200000e+02\n",
      "mean     2.913397e+05\n",
      "std      1.214972e+06\n",
      "min     -2.219330e+00\n",
      "25%      3.084000e-02\n",
      "50%      5.665000e-02\n",
      "75%      1.507000e+00\n",
      "max      5.715154e+06\n",
      "dtype: float64\n",
      "==================================================\n",
      "1\n",
      "count    660.000000\n",
      "mean       0.830646\n",
      "std        0.612427\n",
      "min        0.235290\n",
      "25%        0.784680\n",
      "50%        0.789470\n",
      "75%        0.799638\n",
      "max       13.347820\n",
      "dtype: float64\n",
      "==================================================\n",
      "0\n",
      "count    134.000000\n",
      "mean       0.613657\n",
      "std        0.250153\n",
      "min        0.315290\n",
      "25%        0.418588\n",
      "50%        0.439860\n",
      "75%        0.938000\n",
      "max        0.995260\n",
      "dtype: float64\n",
      "==================================================\n",
      "8\n",
      "count    40.000000\n",
      "mean      0.324166\n",
      "std       0.279454\n",
      "min       0.000000\n",
      "25%       0.119165\n",
      "50%       0.284980\n",
      "75%       0.569936\n",
      "max       1.399150\n",
      "dtype: float64\n",
      "==================================================\n",
      "4\n",
      "count    1.950000e+02\n",
      "mean     1.435304e+05\n",
      "std      4.750502e+05\n",
      "min      0.000000e+00\n",
      "25%      6.984400e-01\n",
      "50%      8.430300e-01\n",
      "75%      3.300655e+00\n",
      "max      1.811250e+06\n",
      "dtype: float64\n",
      "==================================================\n",
      "10\n",
      "count    1.020000e+02\n",
      "mean     2.737644e+05\n",
      "std      5.781300e+05\n",
      "min      1.127000e-02\n",
      "25%      1.301750e-02\n",
      "50%      1.324950e-01\n",
      "75%      6.904126e+04\n",
      "max      1.516775e+06\n",
      "dtype: float64\n",
      "==================================================\n",
      "3\n",
      "count    34.000000\n",
      "mean      0.871541\n",
      "std       0.240911\n",
      "min       0.303400\n",
      "25%       0.865332\n",
      "50%       1.000000\n",
      "75%       1.000000\n",
      "max       1.000000\n",
      "dtype: float64\n",
      "==================================================\n",
      "7\n",
      "count    20.000000\n",
      "mean      0.624592\n",
      "std       0.077500\n",
      "min       0.461680\n",
      "25%       0.535750\n",
      "50%       0.669965\n",
      "75%       0.680540\n",
      "max       0.699000\n",
      "dtype: float64\n",
      "==================================================\n",
      "15\n",
      "count       71.000000\n",
      "mean      8009.539328\n",
      "std       4038.144855\n",
      "min          0.432800\n",
      "25%       6479.938000\n",
      "50%       7274.296000\n",
      "75%       9145.448000\n",
      "max      36289.171580\n",
      "dtype: float64\n",
      "==================================================\n",
      "18\n",
      "count    11.000000\n",
      "mean      0.507136\n",
      "std       0.168680\n",
      "min      -0.000720\n",
      "25%       0.552235\n",
      "50%       0.554760\n",
      "75%       0.557215\n",
      "max       0.583810\n",
      "dtype: float64\n",
      "==================================================\n",
      "14\n",
      "count    2.000000\n",
      "mean     0.641615\n",
      "std      0.503326\n",
      "min      0.285710\n",
      "25%      0.463662\n",
      "50%      0.641615\n",
      "75%      0.819568\n",
      "max      0.997520\n",
      "dtype: float64\n",
      "==================================================\n",
      "19\n",
      "count    6.000000\n",
      "mean     0.809333\n",
      "std      0.012817\n",
      "min      0.792000\n",
      "25%      0.802000\n",
      "50%      0.808000\n",
      "75%      0.820000\n",
      "max      0.824000\n",
      "dtype: float64\n",
      "==================================================\n",
      "13\n",
      "count    2.000000\n",
      "mean     1.955580\n",
      "std      1.441564\n",
      "min      0.936240\n",
      "25%      1.445910\n",
      "50%      1.955580\n",
      "75%      2.465250\n",
      "max      2.974920\n",
      "dtype: float64\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for func, values in scores.items():\n",
    "    print(func)\n",
    "    ser = pd.Series(values)\n",
    "    print(ser.describe())\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(all_comps, test_size = 0.3, random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.933486117216911\n",
      "MSE: 0.060104456466649754\n",
      "MAE: 0.11319744169031715\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "for note in train_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    \n",
    "    if score >= 1:\n",
    "        continue\n",
    "    \n",
    "    target = note[\"target\"]\n",
    "    target_len = len(target)\n",
    "    target = target[:max_len]\n",
    "    target = np.pad(target, (0, max_len - len(target)),  \"constant\", constant_values = -1)\n",
    "    \n",
    "    X_train.append(np.append(\n",
    "        note[\"encoded_sequence\"], np.append(target, target_len)\n",
    "    ))\n",
    "    \n",
    "    y_train.append(score)\n",
    "        \n",
    "for note in test_data:\n",
    "    score = meta[meta.kernel_id == note[\"kernel_id\"]].kaggle_score.iloc[0]\n",
    "    \n",
    "    if score >= 1:\n",
    "        continue\n",
    "    \n",
    "    target = note[\"target\"]\n",
    "    target_len = len(target)\n",
    "    target = target[:max_len]\n",
    "    target = np.pad(target, (0, max_len - len(target)),  \"constant\", constant_values = -1)\n",
    "    \n",
    "    X_test.append(np.append(\n",
    "        note[\"encoded_sequence\"], np.append(target, target_len)\n",
    "    ))\n",
    "    \n",
    "    y_test.append(score)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
